{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "5e4cdc8f-f722-444d-8dd4-aed7cfa0458a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9466666666666667\n"
     ]
    }
   ],
   "source": [
    "#using iris datasets to create a Kneighbors classifier\n",
    "# creator's note, most of the info up her in the top of->\n",
    "# ->the cell happened AFTER the Iris dataset import at the bootom\n",
    "\n",
    "# import sklearn\n",
    "from sklearn import datasets\n",
    "\n",
    "#IMPORTED LATER DURING fetures splitting\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#imports KNeighborsClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "#imported for cell 58 accuracy score\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "#import 2 point calcutor\n",
    "from scipy.spatial import distance\n",
    "\n",
    "def euc(a,b,):\n",
    "    return distance.euclidean(a,b)\n",
    "\n",
    "#create a brand new class K nearest neighbors\n",
    "class ScrappyKNN():\n",
    "     def fit(self, features_train, labels_train):\n",
    "         self.features_train = features_train\n",
    "\n",
    "     def predict(self, features_test):\n",
    "         predictions=[]\n",
    "         for item in features_test:\n",
    "             label = self.closest(item)\n",
    "             predictions.append(label)\n",
    "         return predictions\n",
    "\n",
    "def closest(self, item):\n",
    "    best_dist = euc(item, self.features_train[0])\n",
    "    best_index = 0\n",
    "    for i in range(1, len(self.features_train)):\n",
    "        dist = euc(item,self.features_train[i])\n",
    "        if distance < best_dist:\n",
    "            best_dist = distance\n",
    "            best_index = i\n",
    "            \n",
    "    return self.labels_train[best_index]\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#import iris datasets as 'iris'\n",
    "iris = datasets.load_iris()\n",
    "\n",
    "# features & labels print to check\n",
    "features = iris.data\n",
    "\n",
    "labels = iris.target\n",
    "\n",
    "# model targeting category split training data & test data -- this takes the data and puts half -->\n",
    "# -->into the testing data and half into the training data. half is determined in the variable labeled 'test_size=.5' as .5 = 1/2 or 50%\n",
    "\n",
    "# split features into features_train and features_test ****added 'from sklearn.model_ selection import train test split ' after sklearn import at top\n",
    "# add features_train, features_test,labels_train, labels_split which wil divide the features into two seperate groups and the labels do the same\n",
    "\n",
    "# this will equal = the train and test features are two seperate groups(4 total in this case) and will seperate into two labels groups as well\n",
    "\n",
    "features_train, features_test,labels_train, labels_test = train_test_split(features, labels, test_size=.5)\n",
    "\n",
    "my_classifier = ScrappyKNN() # this is added after the KNN was designed and is not part of our dataset import or setup\n",
    "\n",
    "#calls KNeighborClassifier my_classifier\n",
    "my_classifier = KNeighborsClassifier()\n",
    "\n",
    "# call a function to prepare , load and predict\n",
    "my_classifier.fit(\n",
    "    features_train , labels_train\n",
    ")\n",
    "\n",
    "# pass in the test data\n",
    "prediction = my_classifier.predict(features_test)\n",
    "\n",
    "#import module and get accuracy score\n",
    "print(\n",
    "    accuracy_score\n",
    "    (labels_test, prediction)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "476c1b30-80ab-4a9b-890f-03deeb9a93d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Virginica\n"
     ]
    }
   ],
   "source": [
    "# creating a unique instance of flower and attempt to predict a flower\n",
    "\n",
    "# should predict to a Virginica flower or value of 2\n",
    "# pass the array into the classifier and labels it iris_prediction\n",
    "iris1 = [[6.4,3.5,5.9,2.9]]\n",
    "\n",
    "iris_prediction = my_classifier.predict(iris1)\n",
    "\n",
    "\n",
    "# identifying the label in a huamn-in-the-loop friendly way\n",
    "# teacher corrects tag from iris1 to iris_prediction\n",
    "if iris_prediction[0] == 0:\n",
    "    print('Setosa')\n",
    "if iris_prediction[0] == 1:\n",
    "    print('Versicolor')\n",
    "if iris_prediction[0] == 2:\n",
    "    print('Virginica')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "659eebba-bbea-446e-a552-d537876d6ddc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[6.4, 3.5, 5.9, 2.9]]\n"
     ]
    }
   ],
   "source": [
    "print(iris1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "84a7a6aa-4d4b-4429-b9a5-0d02cec913b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Virginica\n",
      "Iris I was an Oscar Mayer Wiener\n",
      "looney toons\n"
     ]
    }
   ],
   "source": [
    "looney = iris_prediction[0] ==2\n",
    "if iris_prediction[0] == 2:\n",
    "    print('Virginica') \n",
    "   \n",
    "toons = iris_prediction[0]=2\n",
    "if iris_prediction[0]>=0:\n",
    "    print('Iris I was an Oscar Mayer Wiener')\n",
    "    print('looney toons')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "f2419b0d-bf36-4bdd-98ee-5ddcb53180fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(True, 2)"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "looney, toons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "da83d04b-4021-4c64-8366-b0a14d5db4fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looney: True Toons: 2\n"
     ]
    }
   ],
   "source": [
    "print('Looney:',looney,'Toons:', toons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "a575f2c1-916a-43aa-9030-a4902fc4f52c",
   "metadata": {},
   "outputs": [],
   "source": [
    "del toons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "fe8c6e0c-e620-4fbd-b996-b957121c04e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looney: True & Toons: 2\n"
     ]
    }
   ],
   "source": [
    "print('Looney:',looney,'&','Toons:', toons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "a265093b-b23a-4ac4-a9c8-b832393f8945",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looney: True\n",
      "     &\n",
      "Toons: 2\n"
     ]
    }
   ],
   "source": [
    "print('Looney:',looney)\n",
    "print('     &')\n",
    "print('Toons:', toons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70506fd1-74a6-4113-8eb6-dae7b842cfce",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
